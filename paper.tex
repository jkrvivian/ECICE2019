\documentclass[journal,10pt,a4paper]{IEEEtran}

\usepackage[english]{babel}
\usepackage{url}
\usepackage{multicol}
\usepackage{multirow}
\usepackage{url,hyperref,graphicx,float,times}
\usepackage{textcomp}
\usepackage{cite}
\usepackage[caption=false,font=footnotesize]{subfig}
\usepackage{amsmath}
\graphicspath{ {./images/} }

\begin{document}
\title{\Large\textbf{Decentralized Data Marketplace to Enable Trusted Machine Economy}}
\author{
    \large Zan-Jun Wang\IEEEauthorrefmark{3}, Ching-Hua (Vivian) Lin\IEEEauthorrefmark{2}, Yang-Hao Yuan\IEEEauthorrefmark{4}, Ching-Chun (Jim) Huang\IEEEauthorrefmark{1}

    \IEEEauthorblockA{\normalsize\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}Department of Computer Science and Information Engineering, National Cheng Kung University} \\
    \IEEEauthorblockA{\normalsize\IEEEauthorrefmark{3}Department of Computer Science and Information Engineering, National Taiwan University} \\
    \IEEEauthorblockA{\normalsize\IEEEauthorrefmark{4}BiiLabs, Co., Ltd.} \\

    \IEEEauthorblockA{\normalsize\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}No.1, University Road, \IEEEauthorrefmark{3}No.1, Sec. 4, Roosevelt Road} \\

    \IEEEauthorblockA{\normalsize\IEEEauthorrefmark{1}\IEEEauthorrefmark{2}Tainan City, Taiwan (R.O.C.), \IEEEauthorrefmark{3}Taipei City, Taiwan (R.O.C.)} \\

    \IEEEauthorblockA{\normalsize\IEEEauthorrefmark{1}jserv@ccns.ncku.edu.tw, \IEEEauthorrefmark{2}jkrvivian@gmail.com, \IEEEauthorrefmark{3}twzjwang@gmail.com, \IEEEauthorrefmark{4}yanghau@biilabs.io}
}

\maketitle
\section*{\normalsize\textbf{Abstract}}
Transacting IoT data must be different in many respects to build much-needed trust in data marketplaces, trust that will be key to their sustainability. Data generated internally to an organization is usually not enough to remain competitive, enhance customer experience, and improve strategic decision-making. In this paper, we propose a novel approach to construct IoT-enabled data marketplace by decentralized and trustless architecture, posting the trade records but also including the transaction process on the distributed ledgers. It can efficiently enhance the degree of transparency, since all interactions with smart contracts will be written on-chain. Storage via an end-to-end encrypted message channel allows emitting and accessing trusted data stream over the distributed ledgers regardless of the size or cost of the device, simultaneously making a verifiable Auth-compliant request to the platform. Furthermore, the platform will complete matching, trading and refunding process without the human intervention which also protects the rights of data providers and consumers through a trading policy written on the smart contract, and finally apply evolutionary game theory to the machine economy.
\begin{IEEEkeywords}
    streaming data, crowd sensing, data marketplace, decentralization
\end{IEEEkeywords}

\section{\normalsize\textbf{Introduction}}
The growth of data marketplaces is an inevitable result of the IoT (Internet of Things) revolution. As physical assets such as ships, factories, vehicles, farms and buildings become digital, their digital twins will gradually act as secure data exchanges.\cite{digitaltwin}\cite{AutonomousDriving} As data streams surge across silos and carry value across organizations, traditional value chains will transition into a web of value. This paradigm shift will be more complex to administer, forcing businesses to rethink their competitive play as part of these ecosystems. Data marketplaces will emerge as a means to exchange data, monetize data streams and provide the basis of new business models. We refer to this new wave of value creation, for the Internet of Everything, as the "Economy of Things." There are three main barriers to achieving data marketplace:
\begin{enumerate}
    \item Data owners do not have much control over their data and their data is locked in silos managed by products and services companies.
    \item Data owners only have access to their own data which has little value when it comes to knowledge discovery.
    \item Data owners do not know how to discover knowledge from raw data.
\end{enumerate}

To overcome these barriers, we implemented IoT-enabled data marketplace and sensor data submission functionalities which are intended to be very lightweight and capable of running on embedded devices. They will only need to perform Tangle operations (e.g., producing and consuming secure channels) and communicate with decentralized facilities, which do not rely on single-source network infrastructure. This proposed reference architecture includes functions that could be mapped to different stakeholders, and multiple functions can be implemented by the same administrative stakeholder in a given operational deployment.
\begin{enumerate}
    \item Data Sellers are entities that deploy an IoT infrastructure, for example smart energy meters. These entities are interested in selling the collected data or subsets of that data.
    \item Managed Data Lakes would typically store a massive amount of data and metadata to enable data discovery.
    \item Data Buyers consuming data streams or downloading data sets are interested in the additional value that external data can bring to their internal data.
\end{enumerate}

Take the use case of the Airbox\cite{LASS} for instance. Every household with an Airbox device can collect air quality records automatically and autonomically, rather than passively accept the outcomes from the centralized authorities. To protect privacy, data should be encrypted before on-chain. As for data reliability, we extended the backbone design of the Airbox to interoperate smart-contract-oriented structure to write down every transaction. At the same time, data on-chain will send a verifiable request to mark itself as "being tradeable." This step enables buyers to review and bargain at will. Last but not least, payments will be stored on the smart contracts until the transactions are confirmed. The entire sequence is illustrated in Figure \ref{fig:airbox}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{airbox}
    \caption{IoT-enabled personal air quality assistant.}
    \label{fig:airbox}
\end{figure}

\section{\normalsize\textbf{Related Work}}
As the economic value of huge amount of data emerges, several researchers have started to explore the design of data marketplace. The Third Party Auditors (TPAs)-based frameworks\cite{TPA} is far from being satisfactory due to the unstandardize data format dynamic nature of IoT data. Therefore, a decentralized data integrity validation and trading process has been proposed in recent years, and distributed ledger technologies (DLTs) is considered a solution, which has the immutable data storage feature that the existence of data can be trusted and no longer rely on any third party authority.

Data Integrity as a Service (DIaaS) is a blockchain-based framework for data integrity proposed by Liu et al.,\cite{DIaas} which is a Cloud Server Service (CSS) and allows both data provider and consumer to validate data integrity by comparing hashes on Ethereum smart contracts\cite{smartContract} and cloud servers. Moreover, Ethereum smart contract can also realize the purchase agreement, including authoriziation and penalization. However, the architecture of DIaaS needs high trust on the CSS. If CSS is malicious or has crashed, losses to both providers and consumers will result. Also, performance analysis shows that IoT devices have low efficiency interacting with Ethereum due to the time-consuming Proof-of-Work(PoW) process.

To address the inefficiency of the Blockchain, \textbf{IOTA}\cite{IOTAwhitepaper} is a cryptocurrency for the IoT industry based on a revolutionary distributed ledger technology, the \textbf{Tangle}, which enables zero-transaction. Based on Tangle, \textbf{Masked Authenticated Messaging(MAM)}\cite{MAM}, is provided for a second layer data communication protocol which allows transmission, access, and verification of an encrypted data stream over the Tangle where privacy and integrity meet.

Based on Tangle and MAM, the IOTA foundation launched a data marketplace\cite{IOTADataMarket} which is suitable for IoT streaming data that not only allows data providers to put data on Tangle without any trusted cloud services, but also allow providers and consumers to trade on Tangle with privacy protected and assurance of data integrity from source with MAM. Nevertheless, the platform design is centralized, new devices require manual approval from the IOTA foundation to be visible in the marketplace. Also, interacting with Tangle is still the bottleneck for low-level devices especially in an unstable network or electrically noisy environment.

A different framework design proposed by Gupta, S.Kanhere and Jurdak\cite{3tierDataMarket} could reduce the burden of low-level devices as mentioned. The infrastructure is a 3-tier decentralized data marketplace architectural design with Ethereum smart contracts which consist of providers, consumers and brokers. The broker is a trustless and highly resourced device that will facilitate the trading of data between the consumer and providers. However, the data integrity and authentication of each participant is still forthcoming.  

The sustainability of IoT economic system was under discussion by Dusit Niyato et al.\cite{UtilityStruct}. They evaluated the utility structure of data trading and presented game theory model.  Data marketplace organizers can determine their policies to ensure a sustainable system with the Nash Equilibrium found by game theory and the utility structure. However, refund and subscription mechanism were not mentioned in their work.

Such work proposed different solutions to specific issues of data marketplaces. In this paper, we have an overall design of decentralized data marketplace that handles data integrity and trading procedures, such as buyout and subscibing to future data on distributed ledgers.

\section{\normalsize\textbf{System Architecture}}
Our proposed data marketplace framework is a 3-tier de-centralized architecture with registrars, data providers, data consumers and brokers. 

\subsection{Participants}
There are four major roles in the decentralized data marketplace (Figure \ref{fig:system_design}).

\subsubsection{Registrar}
Registrars have access to create and maintain Registration Contracts, a lookup table of participants in decentralized data marketplace. 


\subsubsection{Data Provider}
Data providers generate and preserve streaming data. With the profit through trading process, they can improve the quality and quantity of data.

\subsubsection{Consumer}
Consumers aspire to obtain streaming data to improve the value of their service. However, it is a significant challenge and cost to collect the desired data by themselves. So they look to purchasing the streaming data from data providers.

\subsubsection{Broker}
Brokers delegate data providers and consumers to perform computing tasks as brokers are expected to have ample resources. Trustworthy brokers that meet the requirement of the conformity assessment are added to the decentralized data marketplace. Once a qualified data provider requests to launch a new product, the broker would charge brokerage fees to deal the trading process and publish their data streams to the MAM channel.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{system_design}
    \caption{The system design of a decentralized architecture which consist of a registrar, data providers, consumers and brokers.}
    \label{fig:system_design}
\end{figure}

\subsection{Components}
\subsubsection{Masked Authenticated Messaging}
MAM is a second layer data communication protocol built on the feeless and scalable IOTA network. It resolves the challenges to publish encrypted streaming data to the distributed ledgers with session keys to channel, which indicates that each address is derived from its previous one. In other words, with channel root (aka the first message of a channel) and its session key, all data becomes accessible and validatable. Furthermore, each user can create multiple channels as possible. See Figure \ref{fig:mam_channel}

\begin{figure}[h]
    \centering
    \includegraphics[width=0.4\textwidth]{mam_channel}
    \caption{A user could create multiple MAM channels}
    \label{fig:mam_channel}
\end{figure}

\subsubsection{TangleID}
The TangleID\cite{TangleID} is a self-sovereign identity system based on IOTA that does not require any third-party authority to verify an identity and its digital footprints. TangleID converts digital footprints into Decentralized Identifiers (DIDs)\cite{DID}Documents defined by W3C and publishes to MAM channels. Each participant is required to register on TangleID and performs digital signature with key pairs recorded on DID Documents, thus participants' identity could be easily verified and data persistency of a product could be ensured.

\subsubsection{Ethereum Smart Contract}
Smart contract is a protocol for formulating agreement on a blockchain that provides verification and execution of the contract. The code in the smart contract can interact with other contracts, make decisions, store data and transfer cryptocurrency. All conditions and states established in the contract are enforeced with transparency. The appearance of smart contracts meet different requirements of trading pattern.

\subsubsection{Blind Signature}
Blind signature\cite{blindSig} is used to prevent the situation that the a broker would stole data if a session key is not encryted. In fact, blind signature is a form of digital signature where the message is first "blinded" by a random "blinding factor", and then passed to a signer to confirm. The encrypted message, along with the blinding factor, can be later verified with the signer’s public key.

\subsubsection{IPFS}
Inter-Planetary File system(IPFS)\cite{IPFS} is a peer-to-peer network for storing and accessing files, websites, applications, and data in a distributed file system which is not maintained with certain nodes or entities but all IPFS users. In our proposed architecture, brokers are responsible for publishing metadata to IPFS, including titles, data provider information and data preview, in order to provide users with searching capabilities.

\section{\normalsize\textbf{Trading Model}}
In the following, we describe the data trading process in detail and adapt game theory to ensure the sustainability of our tading model. To participate a data marketplace, data providers and consumers have to register first. Then data provider can launch its product on the marketplace. Once a product is launched, it is searchable and can be subsequently traded. The whole trading and refunding process is defined in smart contracts which are easily traceable and irreversible.

To evaluate trading model with game theory, we divide every piece of data products into two categories by the quality and accuracy, the \textbf{decent data} that consumers are willing to buy and \textbf{unacceptable data} that consumers would stop buying. Though refund is a major topic in our research, it is not discussed in game theory evaluation section. Since consumers pay off once to Purchase Contract for each merchandise, the subscription fee is either paid to providers or returned automatically. That is, both providers and consumers do not charge for extra fees during refund process.

\subsection{Participants Registration}
At the beginning, the registrar creates a Registration Contract, which maintains all participants' information, including their DID documents and public keys. Everyone can query others' public keys for validation but only registrars have permission to add new members. After registration, the launching and trading processes can begin.

\subsection{Launching and Searching Products}
To sell streaming data, a data provider needs to launch a new product on the data marketplace in advance as shown in Figure \ref{fig:launching_product}. 
MAM allows users to create multiple channels as possible, however, the size of a channel is fixed which is decided before creation. Therefore, data providers should decide how to distribute data product into MAM channels, then determine a trusted broker to create a new one and a  Product Contract that records the participants, subscription price, brokerage fee, MAM channel session key, quantity of data and trading process. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.4\textwidth]{launching_product}
	\caption{The process of launching a product.}
	\label{fig:launching_product}
\end{figure}

Brokers certify session keys as well. Only one session key can be signed in each product, so data providers cannot fake a session key to deceive consumers. Figure \ref{fig:key_certification} shows the certification process. When a data provider asks a broker to certify new session key $k$, the data provider uses the broker's public key, which is available in the Registration Contract after the broker's registration, as a blinding factor, and the session key is blinded. Then the data provider sends the blinded session key $Blind(k)$ to the broker. The broker signs the message and returns the signature $Sign(Blind(k))$ to data provider. The data provider removes the blinding factor and obtains the broker's signature of the session key, $Sign(k)$, which is verifiable by consumers.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{key_certification}
    \caption{Session key certification process with blind signature.}
    \label{fig:key_certification}
\end{figure}

The contract address and product description will be stored in a file which is uploaded to IPFS. Consumers can search the desired product by keywords or tags. The consumer then evaluates the product and initiates the trading with the data provider if the consumer is interested in subscribing to the data.

\subsection{Trading}
The entire trading process is as shown in Figure \ref{fig:trading_product}. Once a consumer who wants to subscribe certain streaming data that is generated in the future pays a subscription fee to the Product Contract, it is added to the consumers list automatically by the smart contract. 

\begin{figure}[h]
	\centering
	\includegraphics[width=0.4\textwidth]{trading_product}
	\caption{The process for the product trading.}
	\label{fig:trading_product}
\end{figure}

Next, session key $k$ should be exchanged between the data provider and consumers as shown in Figure \ref{fig:key_exchange}. The data provider can obtain public keys of each consumer from the Registration Contract. For each consumer, the data provider encrypts the session key and broker's signature with the consumer's public key and sends the ciphertext $Encrypt(k + Sign(k))$ to the Product Contract. Consumers listen to the smart contract event which is triggered when the ciphertext is updated, and decrypt the ciphertext to obtain the session key $k$ and signature $Sign(k)$.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{key_exchange}
	\caption{Session key exchange process between the data provider and consumer.}
	\label{fig:key_exchange}
\end{figure}

Consumers can obtain the broker's public key on the Registration Contract as well, so they can verify that the signature is valid and the session key is the only one that is certified by the broker. Afterward, encrypted data is published to the MAM channel, and consumers can obtain and decrypt it with the session key.

\subsection{Refunding}
It is probable that the streaming data sources are delayed or even interrupted after the consumers pay the subscription fee. To protect consumer rights, the subscription fee are not transferred to the data provider until data is generated and published to the MAM channel. If the expected data is not available, consumers can request refunds. We assume that a very small percentage of consumers in the Product Contract are irrational and/or malicious. Each consumer can vote for a refund at any time. If the ratio of consent votes of refunding is higher than the $threshold$ at the $i$th piece of data, the subscription fee is proportionally transferred to the data provider, broker and every consumer. The subscription fee can be prorated as below:

\begin{equation}
    F_{DataProvider}(i) = N price \frac{i-1}{M} (1-F_{b}) -F_{t}
\end{equation}

\begin{equation}
    F_{Broker}(i) = N price \frac{i-1}{M} F_{b} -F_{t}
\end{equation}

\begin{equation}
    F_{Consumer}(i) = price \frac{M-i+1}{M} -F_{t}
\end{equation}

where $price$  is the subscription price, $M$ is the number of expected data samples, $F_{b}$ (\%) is the brokerage fee which is expressed as a percentage, $F_{t}$ is the transaction fee of the smart contract, $N$ is the number of consumers in this contract.

To refund or withdraw subscription fee from the smart contract, data provider, broker, and consumer send a transaction to execute the smart contract and are responsible for transaction fee. We assume that only a half of the expected records are published to the MAM channel. When $F_{b}$ is 5\%, the data provider and broker can withdraw a half of total subscription fee from the smart contract and 5\% of the subscription fee belongs to the broker while the remaining belongs to the data provider. For consumers, they can get half of the subscription fee refunded which should be deducted the transaction fee.

On the other hand, we would consider the situation that one of the consumers requests a refund in our future work. When the consumer is disappointed with the data quality, it may request a refund. Its permit should be cancelled while other consumers are unaffected.

\subsection{Game Theory Evaluation}
Game Theory is a methodology to discuss strategic interaciton among game players. If we can ensure Nash Equilibrium of decentralized data marketplace exists at certain acceptable range, then we can promise the sustainability of decentralized data marketplace. Fan Liang et al\cite{SurveyBigDataPricing} listed several different types of game theory models which are applied on data pricing. We employed repeated game to build our game theory model. Repeated game consists of several repetitions of the same base game which meets the scenario of data subscription.

Figure.\ref{fig:decision_tree} shows the decision tree to depict the the repeated game we used. Each level in this decision tree represents each round of data transmission from data provider to consumers, and the consumers would pay subscription fee, $p_s$, each person. The sum of all the subscription fee pays to data provider is denoted as $P_s$.

\begin{figure} \centering \includegraphics[width=3.3in]{decision_tree} \caption{Decision Tree}
    \label{fig:decision_tree} \end{figure}
For every $n$ round, the data provider would pay $C_{maintain}$ to enhance the sensors that data provider owns. We call this as a maintain period. Moreover, the value of data and the cost of maintenance will decrease as time pass, so we introduce a discounted factor $\beta$ to depict this phenomena.

We have these following assumptions:
\begin{enumerate}
    \item  We assume consumers are rational. \label{rational_man}
    \item  Each data provider monopoly of the product they produced. \label{monopoly}
    \item  Subscription fee only depends on data quality. \label{fee_vs_quality}
    \item  At least 51\% of consumers are in the same group which has complete information exchange.\label{51_in_group} 
    \item  One of the consumers who has complete information exchange with other 51\% buyers has the ability to examine the data quality. \label{1_in_51}
\end{enumerate}

According to \textbf{assumption(\ref{rational_man})}, we learn that few consumers would take malicious actions in this system, since all the consumers are rational.

\textbf{Assumption(\ref{monopoly})} implies there is no other data providers provide the same product in Data Marketplace. In this way, we can consider each provider's behavior independently. That means this decision tree represent the behavior of only one data provider.

From \textbf{assumption(\ref{51_in_group})}, we derive one thing that once one of any consumer in that group launches voting for stopping buying data (in other words, the comsumer annonces the data quality is not acceptable), they would succeed in rejecting the processing subscription.

\textbf{Assumption(\ref{1_in_51})}  implies if unacceptably low accuracy data are delivered to consumers, the examiner will spread this information out.


Based on the description above, the discounted sum of payoff for our repeated game is
\begin{equation} \label{payoff}
    \sum_{i=0}^{m - 1}{\beta^{in}\cdot [(\sum_{j=0}^{n - 1} \beta^j \cdot P_s) - C_{maintain}]}
\end{equation}

Al-Fagih et al. presented\cite{DataPrice} $P_s$ is sigmoid function of $P_r$, and based on rule of thumb $C_{maintain}$ is about a exponential function of $P_r$. We can substitute $P_s$ and $C_{maintain}$ with $P_r$ into Eq. (\ref{payoff}), then we can find out the Nash Equilibrium of repeated game.

\subsubsection{Numerical Example}
To evaluate the behavior of the model we presented, first, we would express the function of $P_s$ and $C_{maintain}$ as function of $P_r$ respectively. Therefore, the sum of subscription fee of all subscriber can be expressed as

\begin{equation} \label{sub_fee}
P_s = R \frac{e^{a (P_r - b)}}{1 + e^{a (P_r - b)}}
\end{equation}

where $a$ and $b$ are tuning factors, and $R$ is the maximun data value.
And we would express the cost of maintenance as

\begin{equation} \label{C_mtn}
C_{maintain} = ce^{P_r - d}
\end{equation}
Where $c$ and $d$ is tuning factor.

Substitute Eq. (\ref{sub_fee}) and Eq. (\ref{C_mtn}) into Eq. (\ref{payoff}). We can derive
\begin{equation} \label{payoff_Pr}
\sum_{i=0}^{m - 1}{\beta^{in}\cdot [(\sum_{j=0}^{n - 1} \beta^j \cdot R \frac{e^{a (P_r - b)}}{1 + e^{a (P_r - b)}}) - ce^{P_r - d}]}
\end{equation}

Let tuning factors $, a = 0.15, b = 50, R = 10000, c = 1, d = 88$, and there is only one maintenance period has happened and one maintenance period consists of 12 rounds which means $m = 1, n = 12$. Based on these parameters, we can plot the payoff function as function of accuracy, $Pr$ which is Figure.\ref{fig:payoff_pic}. The maximun point occurs at $accuracy \approx 92\%$ which we point it out with red dot.
\begin{figure} \centering \includegraphics[width=3.3in]{payoff_pic} \caption{Payoff Function}
    \label{fig:payoff_pic} \end{figure}

Figure.\ref{fig:payoff_pic} illustratres the market mechanism of the subscription trading policy we used under the decentralized data marketplace. First, data providers have weak motivation to operate their sensor in low accuracy, since the incentive of low quality data is mush less than moderate quality data. Second the great deficit at high accuracy is mostly drived by the rapid increasing of maintenance cost. Thus, if the maintenance fee to achieve decent data quality is under a fair price range, then data provider will automatically provide data with high enough data quality under our assumptions.

\section{\normalsize\textbf{Future Work}}
%Data Auction
The data auction process is a data trading mechanism and an economically-driven scheme that establishes corresponding prices of data products through bidding process between consumers and providers. While there has been many auction models\cite{BigPicDataMarket} in several areas, only a few of research focus on third-party auction platform. Our proposed decentralized data marketplace protects the privacy of participants which reveals the minimum information for validation and reduces the suspicion of trust to centralized parties or auctioneers. However, the auction process between multiple participants and analysis of potential threats are still critical issues that need to be resolved. The game theory model presented in this work, we assume each data provider's behavior is independent. However, normally there would be multiple data providers provide similar product (substitution). Only one provider is taken into considerations at present.

 
% ---- Bibliography ----
\bibliographystyle{IEEEtran}
\bibliography{references}
\end{document}
